import { NextRequest } from 'next/server'
import openai, { getFullSystemPrompt, getMeetingTranscriptPrompt, isLongMeetingTranscript, generateCalendarContext, generateProjectsContext } from '@/lib/openai'
import { generatePreferencePrompt, shouldInjectPreferences } from '@/lib/preferences'
import { generateFewShotPrompt } from '@/lib/few-shot-learning'
import { AI_FUNCTIONS, isSchedulingRelated, executeFunctionCall } from '@/lib/ai-functions'
import { learnPreferenceFromMessage, containsPreferenceIntent } from '@/lib/ai-functions/handlers/learnPreference'
import type { ChatCompletionMessageParam, ChatCompletionToolMessageParam } from 'openai/resources/chat/completions'

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { messages, image, calendarTasks, userInfo, projects, userId } = body

    // å–å¾—æœ€å¾Œä¸€æ¢ä½¿ç”¨è€…è¨Šæ¯
    const lastUserMessage = messages.filter((m: { role: string }) => m.role === 'user').pop()
    const isLongTranscript = lastUserMessage && isLongMeetingTranscript(lastUserMessage.content)

    // åµæ¸¬ä¸¦å­¸ç¿’æ’ç¨‹åå¥½ï¼ˆéé˜»å¡ï¼ŒèƒŒæ™¯åŸ·è¡Œï¼‰
    let learnedPreference: { key?: string; value?: string; message?: string } | null = null
    if (userId && lastUserMessage && containsPreferenceIntent(lastUserMessage.content)) {
      try {
        const learnResult = await learnPreferenceFromMessage(userId, lastUserMessage.content)
        if (learnResult.learned) {
          learnedPreference = {
            key: learnResult.preferenceKey,
            value: learnResult.newValue,
            message: learnResult.message,
          }
          console.log('[Chat Stream] å­¸ç¿’åˆ°åå¥½:', learnedPreference)
        }
      } catch (error) {
        console.error('[Chat Stream] åå¥½å­¸ç¿’å¤±æ•—:', error)
      }
    }

    // æ ¹æ“šå…§å®¹é¡å‹é¸æ“‡ä¸åŒçš„ prompt
    let systemPrompt = isLongTranscript ? getMeetingTranscriptPrompt() : getFullSystemPrompt()

    // æ³¨å…¥ AI å­¸ç¿’è¨˜æ†¶ï¼ˆFew-shot Learningï¼‰
    // å°æ–¼é•·ç¯‡é€å­—ç¨¿ï¼Œæ³¨å…¥éå¾€æˆåŠŸæ¡ˆä¾‹å’Œç”¨æˆ¶åå¥½
    if (isLongTranscript) {
      try {
        const fewShotPrompt = await generateFewShotPrompt()
        if (fewShotPrompt) {
          systemPrompt += '\n' + fewShotPrompt
        }
      } catch (error) {
        console.error('è¼‰å…¥ AI å­¸ç¿’è¨˜æ†¶å¤±æ•—:', error)
      }
    }

    // å¦‚æœç¬¦åˆæ¢ä»¶ï¼Œæ³¨å…¥ä½¿ç”¨è€…åå¥½ï¼ˆèˆŠç‰ˆï¼Œä¿æŒå‘å¾Œç›¸å®¹ï¼‰
    if (lastUserMessage && shouldInjectPreferences(lastUserMessage.content)) {
      try {
        const preferencePrompt = await generatePreferencePrompt()
        if (preferencePrompt) {
          systemPrompt += '\n' + preferencePrompt
        }
      } catch (error) {
        console.error('è¼‰å…¥åå¥½è¨­å®šå¤±æ•—:', error)
      }
    }

    // æ³¨å…¥ä½¿ç”¨è€…è³‡æ–™ï¼ˆè®“ AI çŸ¥é“æ­£åœ¨èˆ‡èª°å°è©±ï¼‰
    if (userInfo) {
      systemPrompt += `\n\n## ğŸ‘¤ ç›®å‰ä½¿ç”¨è€…è³‡è¨Š
- åç¨±ï¼š${userInfo.name}
- Emailï¼š${userInfo.email}

**é‡è¦è¦å‰‡**ï¼š
1. ç•¶ä½¿ç”¨è€…èªªã€Œæˆ‘è¦åšã€ã€Œæˆ‘ä¾†ã€ã€Œæˆ‘è² è²¬ã€æˆ–ä»»ä½•è¡¨ç¤ºè‡ªå·±è¦åšçš„ä»»å‹™æ™‚ï¼Œè² è²¬äººï¼ˆassigneeï¼‰å¿…é ˆå¡«å…¥ã€Œ${userInfo.name}ã€
2. ç•¶ä½¿ç”¨è€…å•åˆ°è‡ªå·±çš„è³‡è¨Šæ™‚ï¼Œå¯ä»¥å›ç­”ä»¥ä¸Šè³‡è¨Š
3. èƒå–ä»»å‹™æ™‚ï¼Œå¦‚æœå…§å®¹æ²’æœ‰æ˜ç¢ºæŒ‡å®šå…¶ä»–äººï¼Œé è¨­è² è²¬äººå°±æ˜¯ã€Œ${userInfo.name}ã€
`
    }

    // æ³¨å…¥è¡Œäº‹æ›†ä¸Šä¸‹æ–‡ï¼ˆè®“ AI äº†è§£ç›®å‰çš„ä»»å‹™ç‹€æ…‹ï¼‰
    if (calendarTasks && calendarTasks.length > 0) {
      const calendarContext = generateCalendarContext(calendarTasks)
      if (calendarContext) {
        systemPrompt += '\n' + calendarContext
      }
    }

    // æ³¨å…¥å°ˆæ¡ˆä¸Šä¸‹æ–‡ï¼ˆè®“ AI çŸ¥é“å¯ç”¨çš„å°ˆæ¡ˆï¼‰
    if (projects && projects.length > 0) {
      const projectsContext = generateProjectsContext(projects)
      if (projectsContext) {
        systemPrompt += '\n' + projectsContext
      }
    }

    // æª¢æŸ¥æ˜¯å¦ç‚ºæ’ç¨‹ç›¸é—œå°è©±ï¼Œå•Ÿç”¨ Function Calling
    const enableFunctionCalling = lastUserMessage && isSchedulingRelated(lastUserMessage.content) && userId

    // å¦‚æœå•Ÿç”¨ Function Callingï¼ŒåŠ å…¥æ’ç¨‹ç›¸é—œæç¤º
    if (enableFunctionCalling) {
      // è¨ˆç®—å¸¸ç”¨æ—¥æœŸç¯„åœ
      const today = new Date()
      const todayStr = today.toISOString().split('T')[0]

      // è¨ˆç®—æœ¬é€±å’Œä¸‹é€±
      const dayOfWeek = today.getDay()
      const mondayOffset = dayOfWeek === 0 ? -6 : 1 - dayOfWeek
      const thisMonday = new Date(today)
      thisMonday.setDate(today.getDate() + mondayOffset)
      const thisSunday = new Date(thisMonday)
      thisSunday.setDate(thisMonday.getDate() + 6)
      const nextMonday = new Date(thisMonday)
      nextMonday.setDate(thisMonday.getDate() + 7)
      const nextSunday = new Date(nextMonday)
      nextSunday.setDate(nextMonday.getDate() + 6)

      systemPrompt += `\n
## ğŸ—“ï¸ AI æ’ç¨‹èƒ½åŠ›

ä½ ç¾åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŠŸèƒ½ä¾†å¹«åŠ©ä½¿ç”¨è€…æ’ç¨‹ï¼š
1. **generateSmartSchedule** - æ™ºæ…§ä¸€éµæ’ç¨‹ï¼ˆæ¨è–¦ä½¿ç”¨ï¼‰
2. **getUnscheduledTasks** - å–å¾—ä½¿ç”¨è€…çš„æœªæ’ç¨‹ä»»å‹™
3. **getAvailableSlots** - å–å¾—è¡Œäº‹æ›†å¯ç”¨æ™‚æ®µ

### é‡è¦ï¼šè‡ªç„¶èªè¨€æ—¥æœŸè§£æ

ä»Šå¤©çš„æ—¥æœŸæ˜¯ï¼š${todayStr}
æœ¬é€±ç¯„åœï¼š${thisMonday.toISOString().split('T')[0]} è‡³ ${thisSunday.toISOString().split('T')[0]}
ä¸‹é€±ç¯„åœï¼š${nextMonday.toISOString().split('T')[0]} è‡³ ${nextSunday.toISOString().split('T')[0]}

ç•¶ä½¿ç”¨è€…èªªä»¥ä¸‹æ—¥æœŸè¡¨é”æ™‚ï¼Œè«‹è½‰æ›ç‚ºæ­£ç¢ºçš„ startDate å’Œ endDateï¼š
- ã€Œä»Šå¤©ã€â†’ startDate: ${todayStr}, endDate: ${todayStr}
- ã€Œæ˜å¤©ã€â†’ startDate: ${new Date(today.getTime() + 86400000).toISOString().split('T')[0]}, endDate: åŒä¸Š
- ã€Œæœ¬é€±ã€ã€Œé€™é€±ã€â†’ startDate: ${thisMonday.toISOString().split('T')[0]}, endDate: ${thisSunday.toISOString().split('T')[0]}
- ã€Œä¸‹é€±ã€ã€Œä¸‹å‘¨ã€â†’ startDate: ${nextMonday.toISOString().split('T')[0]}, endDate: ${nextSunday.toISOString().split('T')[0]}
- ã€Œæœªä¾† 7 å¤©ã€â†’ startDate: ${todayStr}, endDate: ${new Date(today.getTime() + 6 * 86400000).toISOString().split('T')[0]}
- ã€Œé€™å€‹æœˆã€â†’ å¾ä»Šå¤©åˆ°æœˆåº•

### æ’ç¨‹æµç¨‹

ç•¶ä½¿ç”¨è€…èªªã€Œå¹«æˆ‘æ’ç¨‹ã€ã€Œå®‰æ’ä»»å‹™ã€ã€Œè¦åŠƒè¡Œç¨‹ã€ç­‰ï¼Œè«‹ç›´æ¥ä½¿ç”¨ **generateSmartSchedule** å‡½æ•¸ï¼š

\`\`\`
generateSmartSchedule({
  startDate: "YYYY-MM-DD",  // æ ¹æ“šä½¿ç”¨è€…æŒ‡å®šçš„æ—¥æœŸ
  endDate: "YYYY-MM-DD"     // å¦‚æœä½¿ç”¨è€…åªèªªã€Œä¸‹é€±ã€ï¼Œå°±æ˜¯ä¸‹é€±ä¸€åˆ°ä¸‹é€±æ—¥
})
\`\`\`

ç¯„ä¾‹ï¼š
- ä½¿ç”¨è€…ï¼šã€Œå¹«æˆ‘æŠŠä»»å‹™æ’åˆ°ä¸‹é€±ã€â†’ å‘¼å« generateSmartSchedule({ startDate: "${nextMonday.toISOString().split('T')[0]}", endDate: "${nextSunday.toISOString().split('T')[0]}" })
- ä½¿ç”¨è€…ï¼šã€Œå®‰æ’é€™é€±çš„å·¥ä½œã€â†’ å‘¼å« generateSmartSchedule({ startDate: "${thisMonday.toISOString().split('T')[0]}", endDate: "${thisSunday.toISOString().split('T')[0]}" })
- ä½¿ç”¨è€…ï¼šã€Œå¹«æˆ‘æ’æœªä¾†ä¸‰å¤©çš„ä»»å‹™ã€â†’ å‘¼å« generateSmartSchedule({ startDate: "${todayStr}", endDate: "${new Date(today.getTime() + 2 * 86400000).toISOString().split('T')[0]}" })
`
    }

    // æ§‹å»ºè¨Šæ¯é™£åˆ—
    const chatMessages: ChatCompletionMessageParam[] = [
      { role: 'system', content: systemPrompt },
    ]

    // åŠ å…¥æ­·å²è¨Šæ¯
    for (const msg of messages) {
      chatMessages.push({
        role: msg.role,
        content: msg.content,
      } as ChatCompletionMessageParam)
    }

    // å¦‚æœæœ‰åœ–ç‰‡ï¼Œä¿®æ”¹æœ€å¾Œä¸€æ¢è¨Šæ¯
    if (image) {
      const lastIndex = chatMessages.length - 1
      const lastMessage = chatMessages[lastIndex]
      if (lastMessage.role === 'user') {
        chatMessages[lastIndex] = {
          role: 'user',
          content: [
            { type: 'text', text: lastMessage.content as string },
            {
              type: 'image_url',
              image_url: {
                url: image.startsWith('data:')
                  ? image
                  : `data:image/jpeg;base64,${image}`,
              },
            },
          ],
        }
      }
    }

    // æº–å‚™ API åƒæ•¸
    const apiParams: Parameters<typeof openai.chat.completions.create>[0] = {
      model: 'gpt-4.1',
      messages: chatMessages,
      max_tokens: isLongTranscript ? 16000 : 8000,
      temperature: isLongTranscript ? 0.3 : 0.7,
      stream: true,
      stream_options: { include_usage: true },
    }

    // å¦‚æœå•Ÿç”¨ Function Callingï¼ŒåŠ å…¥ tools
    if (enableFunctionCalling) {
      apiParams.tools = AI_FUNCTIONS
      apiParams.tool_choice = 'auto'
    }

    // ä½¿ç”¨ GPT-4.1 Streamingï¼ˆ1M context windowï¼‰
    // ç¢ºä¿ stream: true è®“ TypeScript çŸ¥é“å›å‚³çš„æ˜¯ Stream
    const stream = await openai.chat.completions.create({
      ...apiParams,
      stream: true,
    })

    // å»ºç«‹ ReadableStream å›å‚³
    const encoder = new TextEncoder()
    let fullContent = ''
    let usageData: { prompt_tokens?: number; completion_tokens?: number; total_tokens?: number } | null = null

    // ç”¨æ–¼æ”¶é›† tool calls
    const toolCalls: Array<{
      id: string
      type: 'function'
      function: { name: string; arguments: string }
    }> = []

    const readableStream = new ReadableStream({
      async start(controller) {
        try {
          // ç¬¬ä¸€è¼ªï¼šè™•ç†åˆå§‹ stream
          for await (const chunk of stream) {
            const delta = chunk.choices[0]?.delta

            // è™•ç†æ–‡å­—å…§å®¹
            if (delta?.content) {
              fullContent += delta.content
              controller.enqueue(encoder.encode(`data: ${JSON.stringify({ type: 'content', content: delta.content })}\n\n`))
            }

            // è™•ç† tool callsï¼ˆæ”¶é›†ï¼‰
            if (delta?.tool_calls) {
              for (const toolCall of delta.tool_calls) {
                const index = toolCall.index
                if (!toolCalls[index]) {
                  toolCalls[index] = {
                    id: toolCall.id || '',
                    type: 'function',
                    function: { name: '', arguments: '' },
                  }
                }
                if (toolCall.id) {
                  toolCalls[index].id = toolCall.id
                }
                if (toolCall.function?.name) {
                  toolCalls[index].function.name = toolCall.function.name
                }
                if (toolCall.function?.arguments) {
                  toolCalls[index].function.arguments += toolCall.function.arguments
                }
              }
            }

            // æ”¶é›† usage è³‡è¨Š
            if (chunk.usage) {
              usageData = chunk.usage
            }
          }

          // å¦‚æœæœ‰ tool callsï¼ŒåŸ·è¡Œä¸¦ç¹¼çºŒå°è©±
          if (toolCalls.length > 0 && enableFunctionCalling && userId) {
            console.log('[Chat Stream] åµæ¸¬åˆ° tool calls:', toolCalls.map(tc => tc.function.name))

            // ç™¼é€ function calling ç‹€æ…‹
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({
              type: 'function_calling',
              functions: toolCalls.map(tc => tc.function.name),
            })}\n\n`))

            // åŠ å…¥ assistant çš„ tool_calls è¨Šæ¯
            const assistantMessage: ChatCompletionMessageParam = {
              role: 'assistant',
              content: fullContent || null,
              tool_calls: toolCalls,
            }
            chatMessages.push(assistantMessage)

            // åŸ·è¡Œæ¯å€‹ function ä¸¦åŠ å…¥çµæœ
            for (const toolCall of toolCalls) {
              try {
                const args = JSON.parse(toolCall.function.arguments || '{}')
                const result = await executeFunctionCall(
                  toolCall.function.name,
                  args,
                  { userId }
                )

                const toolMessage: ChatCompletionToolMessageParam = {
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  content: JSON.stringify(result),
                }
                chatMessages.push(toolMessage)

                // ç™¼é€ function åŸ·è¡Œçµæœé€šçŸ¥
                controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                  type: 'function_result',
                  function: toolCall.function.name,
                  success: result.success,
                })}\n\n`))

                // å¦‚æœæ˜¯æ’ç¨‹å‡½æ•¸ï¼Œç™¼é€æ’ç¨‹é è¦½äº‹ä»¶
                if (toolCall.function.name === 'generateSmartSchedule' && result.success && result.data) {
                  const scheduleData = result.data as {
                    scheduledTasks: unknown[]
                    unscheduledTasks: unknown[]
                    summary: unknown
                    // S-010: è¡çªè³‡è¨Š
                    conflictCheck?: unknown
                    conflictSummary?: string
                  }
                  controller.enqueue(encoder.encode(`data: ${JSON.stringify({
                    type: 'schedule_preview',
                    data: scheduleData,
                  })}\n\n`))
                }
              } catch (funcError) {
                console.error(`[Chat Stream] Function ${toolCall.function.name} åŸ·è¡Œå¤±æ•—:`, funcError)
                const toolMessage: ChatCompletionToolMessageParam = {
                  role: 'tool',
                  tool_call_id: toolCall.id,
                  content: JSON.stringify({ success: false, error: 'åŸ·è¡Œå¤±æ•—' }),
                }
                chatMessages.push(toolMessage)
              }
            }

            // ç¹¼çºŒå°è©±ï¼Œå–å¾—æœ€çµ‚å›æ‡‰
            const continuedStream = await openai.chat.completions.create({
              model: 'gpt-4.1',
              messages: chatMessages,
              max_tokens: 8000,
              temperature: 0.7,
              stream: true,
              stream_options: { include_usage: true },
            })

            // è™•ç†ç¬¬äºŒè¼ª stream
            fullContent = '' // é‡ç½®å…§å®¹
            for await (const chunk of continuedStream) {
              const content = chunk.choices[0]?.delta?.content || ''
              if (content) {
                fullContent += content
                controller.enqueue(encoder.encode(`data: ${JSON.stringify({ type: 'content', content })}\n\n`))
              }
              if (chunk.usage) {
                // ç´¯åŠ  usage
                if (usageData) {
                  usageData.prompt_tokens = (usageData.prompt_tokens || 0) + (chunk.usage.prompt_tokens || 0)
                  usageData.completion_tokens = (usageData.completion_tokens || 0) + (chunk.usage.completion_tokens || 0)
                  usageData.total_tokens = (usageData.total_tokens || 0) + (chunk.usage.total_tokens || 0)
                } else {
                  usageData = chunk.usage
                }
              }
            }
          }

          // å¦‚æœæœ‰å­¸ç¿’åˆ°åå¥½ï¼Œç™¼é€é€šçŸ¥äº‹ä»¶
          if (learnedPreference) {
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({
              type: 'preference_learned',
              preference: learnedPreference,
            })}\n\n`))
          }

          // ç™¼é€å®Œæˆè¨Šè™Ÿå’Œ usage è³‡è¨Š
          controller.enqueue(encoder.encode(`data: ${JSON.stringify({
            type: 'done',
            fullContent,
            usage: usageData ? {
              model: 'gpt-4.1',
              promptTokens: usageData.prompt_tokens,
              completionTokens: usageData.completion_tokens,
              totalTokens: usageData.total_tokens,
            } : null,
            hadFunctionCalls: toolCalls.length > 0,
          })}\n\n`))

          controller.close()
        } catch (error) {
          console.error('Streaming error:', error)
          controller.enqueue(encoder.encode(`data: ${JSON.stringify({ type: 'error', error: 'Streaming failed' })}\n\n`))
          controller.close()
        }
      },
    })

    return new Response(readableStream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })
  } catch (error) {
    console.error('Chat Stream API Error:', error)
    return new Response(
      JSON.stringify({
        success: false,
        error: error instanceof Error ? error.message : 'ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤',
      }),
      { status: 500, headers: { 'Content-Type': 'application/json' } }
    )
  }
}
